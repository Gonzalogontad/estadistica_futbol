{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ra. B AFA 1967 Zona A\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import csv \n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "def HTML_scores_parse (URL):\n",
    "\n",
    "    response = requests.get(URL)\n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    #Busco el contenido de la pagina\n",
    "    mydivs = page.find_all(\"div\", {\"class\": \"post-body entry-content\"})\n",
    "    mydivs=str(mydivs)\n",
    "    #x = mydivs.find(\"1ra. Fecha\")\n",
    "    x = mydivs.find(\"El Torneo\")\n",
    "    if x < len(mydivs):\n",
    "        mydivs=mydivs[x:]\n",
    "    HTML_LABELS=   [('<br/>','\\n'),\n",
    "                    ('<em>',''),\n",
    "                    ('<span style=\"color:#33cc00;\">',''),\n",
    "                    ('<span style=\"color:#cc66cc;\">',''),\n",
    "                    ('<strong>',''),\n",
    "                    ('</strong>',''),\n",
    "                    ('</em>',''),\n",
    "                    ('</span>',''),\n",
    "                    ('<div style=\"clear: both;\">',''),\n",
    "                    ('<div>',''),\n",
    "                    ('</div>',''),\n",
    "                    ('<title>',''),\n",
    "                    ('</title>','')]\n",
    "    #elimino etiquetas HTML para obtener texto plano\n",
    "    for label in HTML_LABELS:\n",
    "        mydivs=mydivs.replace(label[0], label[1])                \n",
    "    \n",
    "    pattern = r'(\\S*\\/\\S*\\/\\S*):? en (.*): (\\D*) (\\d*)\\s?(?:\\((.*)\\))?, (\\D*) (\\d*)\\s?(?:\\((.*)\\))?-?(Nota:\\s?.*.)?'\n",
    "    pattern_date = r'(\\S*\\/\\S*\\/\\S*)'\n",
    "    mydivs=mydivs.replace('\\nNota:','-Nota:') #si se encuantra una nota, se quita \\n para que se anexe al partido\n",
    "    lines = mydivs.splitlines()\n",
    "    \n",
    "    partidos=[]\n",
    "    error_lines=[]\n",
    "    errors=[]\n",
    "    #Parseo los resultados de los partidos\n",
    "    for line in lines:\n",
    "        partido = re.findall(pattern, line)\n",
    "        if partido:\n",
    "            partidos.append(partido[0])\n",
    "        #Si hay error al parsear guardo la linea para correccion manual    \n",
    "        else:   \n",
    "            partido=re.findall(pattern_date, line)\n",
    "            if partido:\n",
    "                partidos.append(partido)\n",
    "                error_line = len (partidos)+1\n",
    "                error_lines.append(error_line)\n",
    "                errors.append(f'Error en linea {error_line}: {line}\\n')\n",
    "\n",
    "\n",
    "\n",
    "    #Output files path\n",
    "    current_dir = ''#str(pathlib.Path(__file__).parent) #Path actual\n",
    "    page_title=page.find('title') #uso el nombre de la pagina web como nombre de los archivos\n",
    "    for label in HTML_LABELS:\n",
    "        page_title=str(page_title).replace(label[0], label[1])\n",
    "    page_title=page_title.replace('historiayfutbol: Argentina: ','')\n",
    "    page_title=page_title.replace('\"','')\n",
    "    #raw_data_path =Path(current_dir+'/output/'+page_title+'_raw.txt')\n",
    "    #csv_path = Path(current_dir+'/output/'+page_title+'.csv')\n",
    "    #csv_error_path = Path(current_dir+'/output/'+page_title+'_errors.txt')\n",
    "    raw_data_path ='output/'+page_title+'_raw.txt'\n",
    "    csv_path = 'output/'+page_title+'.csv'\n",
    "    csv_error_path = 'output/'+page_title+'_errors.txt'\n",
    "    print (page_title)\n",
    "    \n",
    "    #Creo archivo de datos en bruto\n",
    "    with open(raw_data_path, 'w') as file:\n",
    "        file.write (mydivs)\n",
    "\n",
    "    #Encabezado del archivo CSV\n",
    "    header=('Fecha','Lugar','Equipo1','Goles1','Goleadores1','Equipo2','Goles2','Goleadores2','Notas')\n",
    "\n",
    "    #Creo archivo de datos CSV\n",
    "    with open(csv_path, 'w', encoding='utf-8') as file:\n",
    "        file_writer = csv.writer(file)\n",
    "        file_writer.writerow(header)\n",
    "        for row in partidos:\n",
    "            file_writer.writerow(row)\n",
    "\n",
    "    #Creo archivo de errores a corregir manualmente\n",
    "    with open(csv_error_path,'w',encoding= 'utf-8') as file:\n",
    "        file.writelines(errors)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    URLs = [ 'http://josecarluccio.blogspot.com/2009/10/argentina-1ra-b-afa-1967-zona.html',\n",
    "            \n",
    "            \n",
    "    ]\n",
    "\n",
    "    for url in URLs:\n",
    "        HTML_scores_parse(url)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
